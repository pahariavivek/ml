{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## char-rnn using Tensorflow\n",
    "\n",
    "Hands on rnn with Tensorflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading characters from toy data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 1115394 characters, 65 unique.\n"
     ]
    }
   ],
   "source": [
    "data = open('data/shakespeare_tiny.txt', 'r').read()\n",
    "chars = list(set(data))\n",
    "\n",
    "DATASIZE, ALPHASIZE = len(data), len(chars)\n",
    "print('data has %d characters, %d unique.' % (DATASIZE, ALPHASIZE))\n",
    "\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "data_transformed = np.apply_along_axis(lambda x: char_to_ix[x[0]], 0, np.array(list(data)).reshape([1, DATASIZE]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CELLSIZE = 512\n",
    "SEQLEN = 100\n",
    "BATCHSIZE = 100\n",
    "NLAYERS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "2 layer rnn with GRU cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we want flexible batch size and sequence length\n",
    "inputs = tf.placeholder(tf.uint8, [None, None], name='inputs')           # [ BATCHSIZE, SEQLEN ]\n",
    "inputs_encoded = tf.one_hot(inputs, ALPHASIZE, 1.0, 0.0)                 # [ BATCHSIZE, SEQLEN, ALPHASIZE ]\n",
    "targets = tf.placeholder(tf.uint8, [None, None], name='target')          # [ BATCHSIZE, SEQLEN ]\n",
    "targets_encoded = tf.one_hot(targets, ALPHASIZE, 1.0, 0.0)               # [ BATCHSIZE, SEQLEN, ALPHASIZE ]\n",
    "\n",
    "# input state\n",
    "hin1 = tf.placeholder(tf.float32, [None, CELLSIZE], name='hin1')         # [ BATCHSIZE, CELLSIZE]\n",
    "hin2 = tf.placeholder(tf.float32, [None, CELLSIZE], name='hin2')\n",
    "\n",
    "cell1 = tf.contrib.rnn.GRUCell(CELLSIZE)\n",
    "cell2 = tf.contrib.rnn.GRUCell(CELLSIZE)\n",
    "multi_cell = tf.contrib.rnn.MultiRNNCell([cell1, cell2])\n",
    "\n",
    "ht, final_state = tf.nn.dynamic_rnn(multi_cell, inputs_encoded, dtype=tf.float32, initial_state=(hin1, hin2))\n",
    "#ht [BATCHSIZE, SEQLEN, CELLSIZE], internal state for each rolled out cell\n",
    "#final_state ([BATCHSIZE, CELLSIZE], [BATCHSIZE, CELLSIZE]), this is the last state in the sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ht_flat = tf.reshape(ht, [-1, CELLSIZE])                                 # [BATCHSIZE * SEQLEN, CELLSIZE]\n",
    "y_logits = tf.contrib.layers.linear(ht_flat, ALPHASIZE)                  # [BATCHSIZE * SEQLEN, ALPHASIZE]\n",
    "targets_encoded_flat = tf.reshape(targets_encoded, [-1, ALPHASIZE])      # [BATCHSIZE * SEQLEN, ALPHASIZE]\n",
    "\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(labels=targets_encoded_flat, logits= y_logits) # [BATCHSIZE * SEQLEN]\n",
    "loss = tf.reshape(loss, [BATCHSIZE, -1])                                 # [ BATCHSIZE, SEQLEN ]\n",
    "\n",
    "y_prob= tf.nn.softmax(y_logits, name='y_prob')                           # [ BATCHSIZE x SEQLEN, ALPHASIZE ]\n",
    "y_predict = tf.argmax(y_prob, 1)                                         # [ BATCHSIZE x SEQLEN ]\n",
    "y_predict = tf.reshape(y_predict, [BATCHSIZE, -1], name=\"y_predict\")     # [ BATCHSIZE, SEQLEN ]\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#code copied from https://github.com/martin-gorner/tensorflow-rnn-shakespeare\n",
    "def rnn_minibatch_sequencer(data, batch_size, sequence_size, nb_epochs):\n",
    "\n",
    "    data_len = data.shape[0]\n",
    "    # using (data_len-1) because we must provide for the sequence shifted by 1 too\n",
    "    nb_batches = (data_len - 1) // (batch_size * sequence_size)\n",
    "    assert nb_batches > 0, \"Not enough data, even for a single batch. Try using a smaller batch_size.\"\n",
    "    rounded_data_len = nb_batches * batch_size * sequence_size\n",
    "    xdata = np.reshape(data[0:rounded_data_len], [batch_size, nb_batches * sequence_size])\n",
    "    ydata = np.reshape(data[1:rounded_data_len + 1], [batch_size, nb_batches * sequence_size])\n",
    "    for epoch in range(nb_epochs):\n",
    "        for batch in range(nb_batches):\n",
    "            x = xdata[:, batch * sequence_size:(batch + 1) * sequence_size]\n",
    "            y = ydata[:, batch * sequence_size:(batch + 1) * sequence_size]\n",
    "            x = np.roll(x, -epoch, axis=0)  # to continue the text from epoch to epoch (do not reset rnn state!)\n",
    "            y = np.roll(y, -epoch, axis=0)\n",
    "            yield x, y, epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0 cost=4.1774 accuracy=0.0174\n",
      "Epoch=0 cost=3.3174 accuracy=0.1545\n",
      "Epoch=0 cost=3.2951 accuracy=0.1512\n"
     ]
    }
   ],
   "source": [
    "istate = (np.zeros([BATCHSIZE, CELLSIZE]), np.zeros([BATCHSIZE, CELLSIZE]))  # initial zero input state\n",
    "inn = tf.global_variables_initializer()\n",
    "\n",
    "step = 0\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "sess.run(inn)\n",
    "\n",
    "for x, y_, epoch in rnn_minibatch_sequencer(data_transformed, BATCHSIZE, SEQLEN, 10):\n",
    "\n",
    "    # train on one minibatch\n",
    "    feed_dict = {inputs: x, targets: y_, (hin1,hin2): istate}\n",
    "    _, y, ostate, c = sess.run([train_step, y_predict, final_state, loss], feed_dict=feed_dict)\n",
    "\n",
    "    if step % (50*BATCHSIZE * SEQLEN) == 0:\n",
    "        batchloss = np.mean(c)\n",
    "        accuracy = np.mean(np.equal(y_, y))\n",
    "        print(\"Epoch={} cost={:.4f} accuracy={:.4f}\".format(epoch, batchloss, accuracy))\n",
    "    # loop state around\n",
    "    istate = ostate\n",
    "    step += BATCHSIZE * SEQLEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: rnn_char_seq.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess, \"rnn_char_seq.ckpt\")\n",
    "print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUNCCEUSEUSSSUEESSZZUEEEUUUUUUZSEUZUUEEESSEEZZEEUUSZEZEUEZUEEUZZUEEEUZUSEZZEEEZEZEUSEZEUZUES:\n",
      "TEO:\n",
      "Whyour hare that heavist on marther are hear are.\n",
      "\n",
      "COMINLEN:\n",
      "I wall we the to mant than with hither her hath\n",
      "\n",
      "Porent tore ard ant to mere.\n",
      "\n",
      "PETEN:\n",
      "A dine seare that the coure that thane shere hare.\n",
      "\n",
      "CORINEO:\n",
      "And to mere thee tore wore he prate to the there.\n",
      "\n",
      "CARINCE:\n",
      "Ard the that she the tore wored ard and thee the there and\n",
      "And the the cande the prowe than whith the wither.\n",
      "\n",
      "CARIOLA:\n",
      "That to here the thes and thee to tour hish and and hither.\n",
      "\n",
      "CORENEO:\n",
      "And well, to the sore the withe so to to that hath\n",
      "\n",
      "That In mant our that har her have to have the that here\n",
      "To the har have the thes to hare the partherest tor here\n",
      "That thathe thand hith that to the prouth soull.\n",
      "\n",
      "PERENES:\n",
      "Whan she the sore har have toust thee the wither and her\n",
      "The come the cond to the paines to the panter here\n",
      "\n",
      "Ther and tores in will her and are his that the wall\n",
      "To that to to tous tore here her hit soures\n",
      "That the par"
     ]
    }
   ],
   "source": [
    "#code copied from https://github.com/martin-gorner/tensorflow-rnn-shakespeare\n",
    "def sample_from_probabilities(probabilities, topn=ALPHASIZE):\n",
    "    p = np.squeeze(probabilities)\n",
    "    p[np.argsort(p)[:-topn]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    return np.random.choice(ALPHASIZE, 1, p=p)[0]\n",
    "\n",
    "gx = char_to_ix[\"L\"]  #starting with random character 'L'\n",
    "gx = np.array([[gx]])  # shape [BATCHSIZE, SEQLEN] with BATCHSIZE=1 and SEQLEN=1\n",
    "ncnt = 0\n",
    "# initial values\n",
    "gy = gx\n",
    "gh = (np.zeros([1, CELLSIZE], dtype=np.float32), np.zeros([1, CELLSIZE], dtype=np.float32))  # [ BATCHSIZE, INTERNALSIZE * NLAYERS]\n",
    "for i in range(1000):\n",
    "    gyo, gh = sess.run([y_prob, final_state], feed_dict={inputs: gy, (hin1,hin2): gh})\n",
    "\n",
    "    # If sampling is be done from the topn most likely characters, the generated text\n",
    "    # is more credible and more \"english\". If topn is not set, it defaults to the full\n",
    "    # distribution (ALPHASIZE)\n",
    "\n",
    "    # Recommended: topn = 10 for intermediate checkpoints, topn=2 or 3 for fully trained checkpoints\n",
    "\n",
    "    gc = sample_from_probabilities(gyo, topn=2)\n",
    "    gy = np.array([[gc]])  # shape [BATCHSIZE, SEQLEN] with BATCHSIZE=1 and SEQLEN=1\n",
    "    gc = ix_to_char[gc]\n",
    "    print(gc, end=\"\")\n",
    "\n",
    "    if gc == '\\n':\n",
    "        ncnt = 0\n",
    "    else:\n",
    "        ncnt += 1\n",
    "    if ncnt == 100:\n",
    "        print(\"\")\n",
    "        ncnt = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
