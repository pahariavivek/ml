{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf#r.12\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading toy data with 20 vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source = open(\"data/s2s_sources.txt\",'r')\n",
    "source = [[int(word) for word in line.split()] for line in source]\n",
    "\n",
    "target = open(\"data/s2s_targets.txt\",'r')\n",
    "target = [[int(word) for word in line.split()] for line in target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ENCODER_VOCABSIZE = 20 + 3\n",
    "DECODER_VOCABSIZE = 20 + 3\n",
    "\n",
    "ENCODER_CELLSIZE = 512\n",
    "DECODER_CELLSIZE = 512*2\n",
    "\n",
    "BATCHSIZE = 100\n",
    "\n",
    "NLAYERS = 3\n",
    "\n",
    "EOS = 20\n",
    "GO = 21\n",
    "PAD = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#inverse encoder input: TBD\n",
    "#r1.2 takes care of variable size input sequences\n",
    "#make model such that it is independent of batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(tf.int32, [None, None], name=\"encoder_inputs\") # [ BATCHSIZE, MAX_SEQLEN ]\n",
    "encoder_embeddings = tf.get_variable(name=\"encoder_embedding_matrix\",\n",
    "                                     shape=[ENCODER_VOCABSIZE, ENCODER_CELLSIZE],\n",
    "                                     initializer=tf.contrib.layers.xavier_initializer(uniform=True,seed=None,dtype=tf.float32),\n",
    "                                     dtype=tf.float32)\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(encoder_embeddings, encoder_inputs) \n",
    "encoder_input_length = tf.placeholder(tf.int32, [None], name=\"encoder_input_length\") # [ BATCHSIZE ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e_cells = [tf.contrib.rnn.GRUCell(ENCODER_CELLSIZE) for _ in range(NLAYERS)]\n",
    "encoder_cell = tf.contrib.rnn.MultiRNNCell(e_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(outputs, output_states) = tf.nn.bidirectional_dynamic_rnn(encoder_cell, \n",
    "                                encoder_cell, \n",
    "                                encoder_inputs_embedded, \n",
    "                                sequence_length=encoder_input_length,\n",
    "                                dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_outputs = tf.concat(outputs, 2) # [ BATCHSIZE, MAX_SEQLEN, 2*ENCODER_CELLSIZE]\n",
    "encoder_final_states = [tf.concat(x, 1) for x in zip(output_states[0],output_states[1])] # [ BATCHSIZE, 2*ENCODER_CELLSIZE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_input = tf.placeholder(tf.int32, [None, None], name='decoder_input') # [ BATCHSIZE, SEQLEN ]\n",
    "decoder_input_length = tf.placeholder(shape=[None],dtype=tf.int32,name='decoder_input_length')\n",
    "\n",
    "decoder_embeddings = tf.get_variable(name=\"decoder_embedding_matrix\",\n",
    "                                     shape=[DECODER_VOCABSIZE, DECODER_CELLSIZE],\n",
    "                                     initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                     dtype=tf.float32)\n",
    "\n",
    "decoder_input_embed = tf.nn.embedding_lookup(decoder_embeddings, decoder_input) \n",
    "\n",
    "\n",
    "decoder_targets = tf.placeholder(shape=[None, None],dtype=tf.int32,name='decoder_targets')\n",
    "decoder_targets_length = tf.placeholder(shape=[None],dtype=tf.int32,name='decoder_targets_length')\n",
    "\n",
    "batch_size_t = tf.placeholder(tf.int32, [1], name=\"batch_size_t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attention_mech = tf.contrib.seq2seq.BahdanauAttention(DECODER_CELLSIZE, encoder_outputs,memory_sequence_length=encoder_input_length)\n",
    "#num_units: convert memory(hs) W * hs and query(ht) into W * ht num_units size first\n",
    "#memory: The memory to query; usually the output of an RNN encoder.\n",
    "#normalize\n",
    "#probability_fn: Converts the score to probabilities.  The default is @{tf.nn.softmax}.\n",
    "#score_mask_value: (optional): The mask value for score before passing into `probability_fn`. The default is -inf. Only used if`memory_sequence_length` is not None.\n",
    "\n",
    "#def __call__(query, previous_alignments):\n",
    "#score = math_ops.reduce_sum(v * math_ops.tanh(keys + processed_query),[2]) #v * tanh(W * hs + W * ht)\n",
    "#alignments = self._probability_fn(score, previous_alignments) #previous_alignments are ignored in BahdanauAttention\n",
    "\n",
    "##Applying attention wrapper on top most cell\n",
    "d_cells = [tf.contrib.rnn.GRUCell(DECODER_CELLSIZE) for _ in range(NLAYERS)]\n",
    "top_d_cell = tf.contrib.seq2seq.AttentionWrapper(d_cells[-1], attention_mech,output_attention=False)#read AttentionWrapper once more\n",
    "d_cells[-1] = top_d_cell\n",
    "\n",
    "#Step 1: Mix the `inputs` and previous step's `attention` output via `cell_input_fn`. array_ops.concat([inputs, state.attention], -1)\n",
    "#Step 2: Call the wrapped `cell` with this input and its previous state.\n",
    "#Step 3: Score & alignment the cell's output with `attention_mechanism`. alignments(a(s) = self._attention_mechanism(query=cell_output, previous_alignments=state.alignments)\n",
    "#Step 5: Calculate the context vector as the inner product between the alignments and the attention_mechanism's values (memory). sigma(a(s)*hs)\n",
    "#Step 6: attention_layer_size!=None, attention = DenseLayer(attention_layer_size)(array_ops.concat([cell_output, context], 1))\n",
    "#        else:                       attention = context\n",
    "#output_attention == true return attention, next_state or return output, next_state\n",
    "\n",
    "##Updating state of top cell to be equivalent to attention wrapper cell\n",
    "decoder_initial_states = encoder_final_states\n",
    "top_d_state = top_d_cell.zero_state(batch_size_t, tf.float32)\n",
    "top_d_state = top_d_state.clone(cell_state=decoder_initial_states[-1])\n",
    "decoder_initial_states[-1] = top_d_state\n",
    "decoder_initial_states = tuple(decoder_initial_states)\n",
    "\n",
    "decoder_cell = tf.contrib.rnn.MultiRNNCell(d_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_helper = tf.contrib.seq2seq.TrainingHelper(decoder_input_embed, decoder_input_length)\n",
    "#Training Helper\n",
    "#sample(time, outputs) -> argmax(output, -1)\n",
    "#next_inputs(time, outputs, state) -> (allFinished?, decoder_input_embed[time+1], state)\n",
    "\n",
    "decoder_output_layer = tf.contrib.keras.layers.Dense(DECODER_VOCABSIZE)\n",
    "\n",
    "decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, \n",
    "                                          decoder_helper, \n",
    "                                          decoder_initial_states, \n",
    "                                          decoder_output_layer)\n",
    "#step(time, inputs, state)\n",
    "#Step1: cell_outputs, cell_state = self._cell(inputs, state)\n",
    "#step2: if self._output_layer is not None: cell_outputs = self._output_layer(cell_outputs)\n",
    "#step3: sample_ids = self._helper.sample(time=time, outputs=cell_outputs, state=cell_state) which is just argmax\n",
    "#step4: (finished, next_inputs, next_state) = self._helper.next_inputs(time=time,outputs=cell_outputs,state=cell_state,sample_ids=sample_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_outputs, final_state, final_sequence_lengths = tf.contrib.seq2seq.dynamic_decode(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ylogits = final_outputs.rnn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = tf.argmax(tf.nn.softmax(Ylogits),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_weights = tf.ones([BATCHSIZE,tf.reduce_max(final_sequence_lengths)], dtype=tf.float32, name=\"loss_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.contrib.seq2seq.sequence_loss(Ylogits, decoder_targets, loss_weights)\n",
    "train_op = tf.train.AdamOptimizer(1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch(inputs):\n",
    "    sequence_lengths = [len(seq) for seq in inputs]\n",
    "    batch_size = len(inputs)\n",
    "    \n",
    "    max_sequence_length = max(sequence_lengths)\n",
    "    type(max_sequence_length)\n",
    "    \n",
    "    inputs_batch_major = np.ones(shape=[batch_size, max_sequence_length], dtype=np.int32)*PAD\n",
    "    for i, seq in enumerate(inputs):\n",
    "        for j, element in enumerate(seq):\n",
    "            inputs_batch_major[i, j] = element\n",
    "            \n",
    "    return inputs_batch_major\n",
    "\n",
    "def rnn_minibatch_sequencer(X, Y, batch_size, epochs):\n",
    "    inputs = len(X)\n",
    "    for ep in range(epochs):\n",
    "        for i in range(int(inputs/batch_size)):\n",
    "            encoder_input = X[i*batch_size: (i+1)*batch_size]\n",
    "            encoder_input_len = [len(seq) for seq in encoder_input]\n",
    "            y = Y[i*batch_size: (i+1)*batch_size]\n",
    "            decoder_input = [[GO] + seq for seq in y]\n",
    "            decoder_input_len = [len(seq) for seq in decoder_input]\n",
    "            decoder_target =[(seq + [EOS]) for seq in y]\n",
    "            decoder_target_len = [len(seq) for seq in decoder_target]\n",
    "            yield batch(encoder_input),np.array(encoder_input_len),batch(decoder_input),\\\n",
    "            np.array(decoder_input_len),batch(decoder_target),np.array(decoder_target_len),np.array([batch_size]),ep        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a,b,c,d,e,f,g,h = rnn_minibatch_sequencer(source, target, BATCHSIZE,10).__next__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inn = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "sess.run(inn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b,c,d,e,f,g,h in rnn_minibatch_sequencer(source, target, BATCHSIZE, 10):\n",
    "    feed_dict = {encoder_inputs:a,\n",
    "               encoder_input_length:b,\n",
    "               decoder_input:c,\n",
    "               decoder_input_length:d,\n",
    "               decoder_targets:e,\n",
    "               decoder_targets_length:f,\n",
    "               batch_size_t:g}\n",
    "    \n",
    "    _, pred, c = sess.run([train_op, Y_pred, loss], feed_dict=feed_dict)\n",
    "    \n",
    "    print(\"epoch {} loss {}\".format(h, c))\n",
    "    print(pred[:5])\n",
    "    \n",
    "    #e_s = sess.run([encoder_final_states],feed_dict=feed_dict)\n",
    "    #print(e_s)\n",
    "    #logi = sess.run([Ylogits],feed_dict=feed_dict)\n",
    "    #print(logi)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_final_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "using greedy decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_start_token = tf.placeholder(tf.int32, [None], name=\"decoder_start_token\") # [ BATCHSIZE ]\n",
    "decoder_end_token = EOS\n",
    "decoder_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(decoder_embeddings,decoder_start_token,decoder_end_token)\n",
    "#initialize = finished, first_inputs = embedding_lookup(start_token)\n",
    "#next_inputs (time, outputs, state, sample_ids) -> (finished=sample_id==end_token, next_input=embedding_lookup(sample_ids), state)\n",
    "#sample_id is argmax of the output, so decoder should give output which are after softmax\n",
    "\n",
    "decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, decoder_helper, decoder_initial_states,decoder_output_layer)\n",
    "final_outputs, final_state, final_sequence_lengths = tf.contrib.seq2seq.dynamic_decode(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#YlogitsTest = final_outputs.rnn_output\n",
    "#Y_pred_test = tf.argmax(tf.nn.softmax(YlogitsTest),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_seq = np.array([int(x) for x in '1 2 3 4 5 6'.split()], dtype=np.int32)\n",
    "input_seq=input_seq.reshape((1,len(input_seq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_seq_len = np.array(input_seq.shape[1]).reshape((1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_seq, predicted_seq_len = sess.run([final_outputs.sample_id, final_sequence_lengths],\\\n",
    "         feed_dict={decoder_start_token:np.array([GO]) , \n",
    "                    encoder_inputs:input_seq, \n",
    "                    encoder_input_length:input_seq_len,\n",
    "                    batch_size_t:np.array([1])})\n",
    "\n",
    "print(\"{}, {}\".format(predicted_seq[0], predicted_seq_len[0]))#first prediction for batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "using beam search decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_width = 5\n",
    "beamsearch_decoder = tf.contrib.seq2seq.BeamSearchDecoder(decoder_cell,\n",
    "                                                          decoder_embeddings,\n",
    "                                                          decoder_start_token,\n",
    "                                                          decoder_end_token,\n",
    "                                                          decoder_initial_states,\n",
    "                                                          beam_width,\n",
    "                                                          decoder_output_layer)\n",
    "\n",
    "#np.tile(decoder_start_token, beam_width) is applied \n",
    "#therefore, when decoder_start_token = [batch_size]\n",
    "#then decoder_initial_states = ([batch_size*beam_width, cell_size])\n",
    "#therefore, encoder_inputs = ([batch_size*beam_width, seq_len])\n",
    "final_outputs_bs, final_state_bs, final_sequence_lengths_bs = tf.contrib.seq2seq.dynamic_decode(beamsearch_decoder)\n",
    "\n",
    "predicted_seq_bs, predicted_seq_len_bs = sess.run([final_outputs_bs, final_sequence_lengths_bs],\\\n",
    "         feed_dict={decoder_start_token:np.array([GO]) , \n",
    "                    batch_size_t:np.array([beam_width]),\n",
    "                  encoder_inputs: np.tile(input_seq,(beam_width,1)),\n",
    "                  encoder_input_length:np.tile(input_seq_len,beam_width)})\n",
    "\n",
    "print(\"{}, {}\".format(predicted_seq_bs.predicted_ids[0].T, predicted_seq_len_bs[0]))#first prediction for batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess, \"seq2seq_reverse.ckpt\")\n",
    "print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
